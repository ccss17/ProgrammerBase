# 조금은 철학적인 이야기 - 기술적 특이점

---

# Table of Contents

- [미래 ](https://github.com/ccss17/ProgrammerBase/blob/master/future.md#%EB%AF%B8%EB%9E%98)

  - [기술적 특이점 ](https://github.com/ccss17/ProgrammerBase/blob/master/future.md#%EA%B8%B0%EC%88%A0%EC%A0%81-%ED%8A%B9%EC%9D%B4%EC%A0%90)

- [Why the future doesn't need us](https://github.com/ccss17/ProgrammerBase/blob/master/future.md#why-the-future-doesnt-need-us)

  - [내가 커즈와일과 나눈 대화](https://github.com/ccss17/ProgrammerBase/blob/master/future.md#%EB%82%B4%EA%B0%80-%EC%BB%A4%EC%A6%88%EC%99%80%EC%9D%BC%EA%B3%BC-%EB%82%98%EB%88%88-%EB%8C%80%ED%99%94)

    - [기술적 특이점이 도래했을 때의 미래](https://github.com/ccss17/ProgrammerBase/blob/master/future.md#%EA%B8%B0%EC%88%A0%EC%A0%81-%ED%8A%B9%EC%9D%B4%EC%A0%90%EC%9D%B4-%EB%8F%84%EB%9E%98%ED%96%88%EC%9D%84-%EB%95%8C%EC%9D%98-%EB%AF%B8%EB%9E%98)

      - [(1) 기계가 인간의 통제를 받지 않고 스스로 판단하는 것이 허용될 경우](https://github.com/ccss17/ProgrammerBase/blob/master/future.md#1-%EA%B8%B0%EA%B3%84%EA%B0%80-%EC%9D%B8%EA%B0%84%EC%9D%98-%ED%86%B5%EC%A0%9C%EB%A5%BC-%EB%B0%9B%EC%A7%80-%EC%95%8A%EA%B3%A0-%EC%8A%A4%EC%8A%A4%EB%A1%9C-%ED%8C%90%EB%8B%A8%ED%95%98%EB%8A%94-%EA%B2%83%EC%9D%B4-%ED%97%88%EC%9A%A9%EB%90%A0-%EA%B2%BD%EC%9A%B0)

      - [(2) 기계에 대한 인간의 통제가 유지될 경우](https://github.com/ccss17/ProgrammerBase/blob/master/future.md#2-%EA%B8%B0%EA%B3%84%EC%97%90-%EB%8C%80%ED%95%9C-%EC%9D%B8%EA%B0%84%EC%9D%98-%ED%86%B5%EC%A0%9C%EA%B0%80-%EC%9C%A0%EC%A7%80%EB%90%A0-%EA%B2%BD%EC%9A%B0)

    - [왜 현 시대 인류는 기술공학 발전이 주는 위협에 관심을 갖지 않는가?](https://github.com/ccss17/ProgrammerBase/blob/master/future.md#%EC%99%9C-%ED%98%84-%EC%8B%9C%EB%8C%80-%EC%9D%B8%EB%A5%98%EB%8A%94-%EA%B8%B0%EC%88%A0%EA%B3%B5%ED%95%99-%EB%B0%9C%EC%A0%84%EC%9D%B4-%EC%A3%BC%EB%8A%94-%EC%9C%84%ED%98%91%EC%97%90-%EA%B4%80%EC%8B%AC%EC%9D%84-%EA%B0%96%EC%A7%80-%EC%95%8A%EB%8A%94%EA%B0%80)

    - [기술적 특이점의 실현 가능성에 관하여 (1) - GNR 기술의 원료](https://github.com/ccss17/ProgrammerBase/blob/master/future.md#%EA%B8%B0%EC%88%A0%EC%A0%81-%ED%8A%B9%EC%9D%B4%EC%A0%90%EC%9D%98-%EC%8B%A4%ED%98%84-%EA%B0%80%EB%8A%A5%EC%84%B1%EC%97%90-%EA%B4%80%ED%95%98%EC%97%AC-1---gnr-%EA%B8%B0%EC%88%A0%EC%9D%98-%EC%9B%90%EB%A3%8C)

    - [기술적 특이점의 실현 가능성에 관하여 (2) - 초지능을 실행할만큼 강력한 컴퓨터](https://github.com/ccss17/ProgrammerBase/blob/master/future.md#%EA%B8%B0%EC%88%A0%EC%A0%81-%ED%8A%B9%EC%9D%B4%EC%A0%90%EC%9D%98-%EC%8B%A4%ED%98%84-%EA%B0%80%EB%8A%A5%EC%84%B1%EC%97%90-%EA%B4%80%ED%95%98%EC%97%AC-2---%EC%B4%88%EC%A7%80%EB%8A%A5%EC%9D%84-%EC%8B%A4%ED%96%89%ED%95%A0%EB%A7%8C%ED%81%BC-%EA%B0%95%EB%A0%A5%ED%95%9C-%EC%BB%B4%ED%93%A8%ED%84%B0)

    - [기계가 인류를 완전히 대체하는 것에 관하여](https://github.com/ccss17/ProgrammerBase/blob/master/future.md#%EA%B8%B0%EA%B3%84%EA%B0%80-%EC%9D%B8%EB%A5%98%EB%A5%BC-%EC%99%84%EC%A0%84%ED%9E%88-%EB%8C%80%EC%B2%B4%ED%95%98%EB%8A%94-%EA%B2%83%EC%97%90-%EA%B4%80%ED%95%98%EC%97%AC)

  - [GNR 에 관하여](https://github.com/ccss17/ProgrammerBase/blob/master/future.md#gnr-%EC%97%90-%EA%B4%80%ED%95%98%EC%97%AC)

    - [G(유전자공학)에 관하여](https://github.com/ccss17/ProgrammerBase/blob/master/future.md#g%EC%9C%A0%EC%A0%84%EC%9E%90%EA%B3%B5%ED%95%99%EC%97%90-%EA%B4%80%ED%95%98%EC%97%AC)

    - [N(나노테크놀로지)에 관하여](https://github.com/ccss17/ProgrammerBase/blob/master/future.md#n%EB%82%98%EB%85%B8%ED%85%8C%ED%81%AC%EB%86%80%EB%A1%9C%EC%A7%80%EC%97%90-%EA%B4%80%ED%95%98%EC%97%AC)

  - [기술적 특이점에 대한 대안책](https://github.com/ccss17/ProgrammerBase/blob/master/future.md#%EA%B8%B0%EC%88%A0%EC%A0%81-%ED%8A%B9%EC%9D%B4%EC%A0%90%EC%97%90-%EB%8C%80%ED%95%9C-%EB%8C%80%EC%95%88%EC%B1%85)

    - [인류가 미래의 평화를 위하여 합의를 할만한 존재가 아니라는 것에 관하여](https://github.com/ccss17/ProgrammerBase/blob/master/future.md#%EC%9D%B8%EB%A5%98%EA%B0%80-%EB%AF%B8%EB%9E%98%EC%9D%98-%ED%8F%89%ED%99%94%EB%A5%BC-%EC%9C%84%ED%95%98%EC%97%AC-%ED%95%A9%EC%9D%98%EB%A5%BC-%ED%95%A0%EB%A7%8C%ED%95%9C-%EC%A1%B4%EC%9E%AC%EA%B0%80-%EC%95%84%EB%8B%88%EB%9D%BC%EB%8A%94-%EA%B2%83%EC%97%90-%EA%B4%80%ED%95%98%EC%97%AC)

    - [NBC 기술보다 제한하기 어려운 GNR 기술](https://github.com/ccss17/ProgrammerBase/blob/master/future.md#nbc-%EA%B8%B0%EC%88%A0%EB%B3%B4%EB%8B%A4-%EC%A0%9C%ED%95%9C%ED%95%98%EA%B8%B0-%EC%96%B4%EB%A0%A4%EC%9A%B4-gnr-%EA%B8%B0%EC%88%A0)

    - [GNR 기술의 위험성에 대하여](https://github.com/ccss17/ProgrammerBase/blob/master/future.md#gnr-%EA%B8%B0%EC%88%A0%EC%9D%98-%EC%9C%84%ED%97%98%EC%84%B1%EC%97%90-%EB%8C%80%ED%95%98%EC%97%AC)

  - [커즈와일과의 대화 일 년 후](https://github.com/ccss17/ProgrammerBase/blob/master/future.md#%EC%BB%A4%EC%A6%88%EC%99%80%EC%9D%BC%EA%B3%BC%EC%9D%98-%EB%8C%80%ED%99%94-%EC%9D%BC-%EB%85%84-%ED%9B%84)

---

# 미래 

지금까지 역사를 통해 과거를 살펴보았습니다. 하지만 과거는 그 자체로는 아무런 의미가 없습니다. 우리가 과거를 살펴본 이유는 과거를 통하여 미래를 예측하고 그 예측을 기반으로 오늘 어떻게 행동해야 하는지 결정하기 위해서입니다. 여기에서는 저명한 컴퓨터 과학자가 미래에 대하여 이야기한 것을 살펴보겠습니다. 하지만 **미래에 대한 이야기는 항상 불확실하기 때문에 맹신하지 마시고 받아들이실 것은 받아들이시고 거를 것은 거르면서 들으시길 바랍니다.**

## 기술적 특이점 

> 참고 : https://ko.wikipedia.org/wiki/%EA%B8%B0%EC%88%A0%EC%A0%81_%ED%8A%B9%EC%9D%B4%EC%A0%90

> 참고 : https://namu.wiki/w/%EA%B8%B0%EC%88%A0%EC%A0%81%20%ED%8A%B9%EC%9D%B4%EC%A0%90

하지만 그에 앞서서 기술적 특이점이라는 개념에 대한 약간의 사전지식을 가지고 글을 읽으면 이해가 훨씬 잘 됩니다.

**[기술적 특이점(technological singularity)](https://ko.wikipedia.org/wiki/%EA%B8%B0%EC%88%A0%EC%A0%81_%ED%8A%B9%EC%9D%B4%EC%A0%90)이란 인공지능의 발전이 가속화되어 모든 인류의 지성보다 더 뛰어난 초인공지능이 출현하고 다시는 세계를 그 이전으로 되돌릴 수 없는 시점**을 뜻합니다. 특이점이라고 불리우는 이유는 기술발전 속도가 급속도로 변함으로써 그 영향력이 너무 커져서 인간이 세상을 다시는 그 이전으로 되돌리지 못하기 때문입니다. 기술적 특이점의 중요한 특징은 기술이 스스로 기술발전을 하기 시작하고 그 속도가 점차 가속화되어 모든 인류 중에서 가장 뛰어난 지능을 갖고 있는 사람도 더 이상 기술발전 과정과 기술 공학물들을 이해할 수 없다는 것입니다. 누구도 더 이상 기술공학 발전을 이해할 수 없기 때문에 다시는 그 기술공학 결정체들을 과거로 되돌릴 수 없는 상태가 됩니다.

- **1951년 앨런 튜링**이 인간의 지적 능력을 능가하는 기계가 발명될 수도 있다고 다음과 같이 언급합니다.

  *"**생각하는 기계가 발명될 수 있다면 인간의 지능을 금세 따라잡을 수 있을 것**이다. ... 그 시기가 온다면 ... **기계가 권력을 쥐게 될 것**이다. "*

- **(기술적 특이점 개념의 첫 언급)** 인류의 역사를 다시는 이전으로 돌이킬 수 없는 단절을 의미하는 **기술적 특이점을 최초로 언급**한 사람은 설명할 필요가 없는 **위대한 수학자 폰 노이만**이었습니다. 그는 다음과 같이 기술적 특이점을 언급했습니다.

  *"기술의 항구한 가속적 발전으로 인해 **인류 역사에는 필연적으로 특이점이 발생할 것**이며, **그 후의 인간사는 지금껏 이어져 온 것과는 전혀 다른 무언가가 될 것**이다"*

- 이후 **1965년 어빙 존 굿**이 **인간의 개입 없이 스스로 다음 세대를 설계하는 인공지능에 의해 초래되는 "지능 폭발" 로의 기술적 특이점**을 언급했습니다. **1983년 수학자 버너 빈지**는 어빙 존 굿의 지능 폭발을 다음과 같이 언급하며 대중화시켰습니다.

  *"**인간들은 곧 우리의 지능보다 더 뛰어난 지능을 가진 기계를 발명해 낼 것**이다. 그리고 이러한 발명이 이루어질 때 우리는 특이점의 시대를 맞아들이게 될 것이다. 블랙홀의 중심에서 더 이상 되돌아 갈 수 없는 사상의 지평선이 이루어지는 것과 같이, **우리는 더 이상 이전의 무지의 상태로 되돌아 갈 수 없게 될 것**이다. "*

- **2000년에 빌 조이**가 [《Why the future doesn't need us》(왜 우리는 필요없는 존재가 될 것인가?)](https://www.wired.com/2000/04/joy-2/) 을 게시함으로써 기술적 특이점의 개념이 대중들에게 더욱 알려졌습니다.

  - **지금부터 우리는 이 빌 조이의 글을 살펴볼 것입니다.**

- **2005년에는 레이 커즈와일**이 [『특이점이 온다』](https://book.naver.com/bookdb/book_detail.nhn?bid=2627729) 

  <div align="center">

  [![](https://bookthumb-phinf.pstatic.net/cover/026/277/02627729.jpg)](https://book.naver.com/bookdb/book_detail.nhn?bid=2627729)

  </div>

  를 집필하여 기술적 특이점의 개념을 더욱 구체화하고 대중화했습니다. 
  
  > 방학 때나 휴학을 했을 때 한번 읽어보시길 추천합니다. 

# Why the future doesn't need us

> 참고 : https://www.wired.com/2000/04/joy-2/

> 참고 : http://greenreview.co.kr/greenreview_article/1843/

[빌 조이(William Nelson Joy)](https://ko.wikipedia.org/wiki/%EB%B9%8C_%EC%A1%B0%EC%9D%B4)는 역사에 남을 프로그램인 `vi` 편집기와 `java` 의 개발자이고 여러분이 좋아하는 **MacOS** 의 전신인 **BSD Unix** 의 개발자이며 썬 마이크로시스템즈사의 창립자이고 클린턴 대통령의 정보기술 대통령 자문위원회 공동의장이자 미국의 대규모 사회실험의 과학자기술자 그룹의 핵심멤버입니다. 

그가 쓴 **기술공학 발전의 가속화에 대한 경고와 우려를 담은 미래에 대한 글 《Why the future doesn't need us》(왜 우리는 필요없는 존재가 될 것인가?) 을 가볍게 살펴보겠습니다.** 이 글이 발표되자 독일의 주요 신문이 지면에 번역하여 실었고, 영국의 세계적 환경잡지도 이 문제를 특집으로 다뤘고, 스탠퍼드 대학에서 빌 조이를 불러서 그의 견해에 관련하여 치열한 논쟁을 벌였습니다.

빌 조이의 글은 그가 [레이 커즈와일(Raymond "Ray" Kurzweil)](https://ko.wikipedia.org/wiki/%EB%A0%88%EC%9D%B4_%EC%BB%A4%EC%A6%88%EC%99%80%EC%9D%BC)과 나눈 대화로부터 나온 아이디어를 기반으로 작성된 것입니다. 레이 커즈와일은 **Google** 엔지니어링 이사로써 유명한 컴퓨터 과학자, 인공지능 프로그래머, 미래학자입니다. 그는 2013년 PBS 가 선정한 "미국을 만든 인물" 의 기술혁신부문의 16명 중 한 명(16명 가운데에는 에디슨, 벨 등이 있음)으로 뽑혔고, 20개 대학의 명예박사 학위를 갖고 있고 세 명의 미국 대통령이 백악관에 직접 초빙하여 공로훈장을 수여했습니다.

> 제가 미래학에 관한 이야기가 어디까지나 예측이므로 불확실할 수 있고 맹신하면 안되는 내용이라고 말했지만, 아무리 그래도 살펴볼 가치도 없는 내용을 후배들에게 보여주진 않겠지요.

**아래의 내용에서 지칭하는 1인칭 "나" 는 제가 아니라 빌 조이를 뜻합니다.**

## 내가 커즈와일과 나눈 대화

나(**빌조이를 지칭합니다**)는 **1998년 가을 레이 커즈웨일을 만나 대화를 하고 기술 발전에 대한 심각성과 위험성을 느꼈다.** 레이는 기술 발전속도가 점차 가속될 것이고 인간이 로봇이 되거나 로봇과 뒤섞일 것이라고 했다. 

### 기술적 특이점이 도래했을 때의 미래

**프로그래머들이 인간보다 모든 일을 더 잘할 수 있는 기계를 개발했다고 하자.** 이것이 모든 인간의 지능을 뛰어 넘는 인공지능, 즉 초지능이다. 그러면 모든 일이 기계 시스템에 의해 수행될 것이고 인간의 어떤 노력도 불필요하게 된다. 이 시점에서 **(1) 기계가 인간의 통제를 받지 않고 스스로 판단하는 것이 허용**되거나, **(2) 인간의 통제가 유지**되거나 둘 중 하나의 상황이 될 것이다. 

#### (1) 기계가 인간의 통제를 받지 않고 스스로 판단하는 것이 허용될 경우

**기계들이 스스로 판단하는 것이 허용된다면 인류의 운명이 기계에 의해 좌우될 수도 있다.** 어떤 사람은 인간이 기계에게 통제권을 넘겨줄만큼 어리석지 않다고 주장할 수 있다. 하지만 인류가 기계에 점차 의존하면서 언젠가 기계가 내리는 모든 결정을 받아들이는 선택을 할 수밖에 없는 상황이 올 것이다. 왜냐하면 "인간보다 모든 일을 더 잘할 수 있는 기계를 개발했다" 는 가정에 따라서 기계가 인간보다 복잡한 사회 문제에 대하여 훨씬 더 나은 결정을 내리기 때문이다. 이것은 기계의 스위치를 내리는 것이 인간들 자신에게 자살행위가 되는 시점이 온다는 의미이다.
  
#### (2) 기계에 대한 인간의 통제가 유지될 경우

기계에 대한 인간의 통제가 유지되는 경우 **인공지능을 개발한 극소수의 프로그래머에 의하여 기계(인공지능) 시스템이 장악될 것**이다. 극소수 엘리트의 장악은 오늘날과 비슷하지만 두 가지 큰 차이점이 있다. 

1. 첫째, 엘리트가 **대중에 행사하는 통제력이 지금보다 훨씬 더 클 것**이다. 

2. 둘째, 인간의 노동력이 아무런 필요가 없어져서 **인간이 경제적 관점에서는 아무런 가치가 없는 존재가 된다.**

[한스 모라벡(Hans Moravec)](https://ko.wikipedia.org/wiki/%ED%95%9C%EC%8A%A4_%EB%AA%A8%EB%9D%BC%EB%B2%A1)의 책 [『Robot: Mere Machine to Transcendent Mind』(로봇 - 단순한 기계로부터 초월적인 정신으로)](https://www.amazon.com/Robot-Mere-Machine-Transcendent-Mind/dp/0195136306) 는 생물학적 종이 우월한 경쟁자를 만나 살아남는 경우가 거의 없다는 것을 알려준다. 인간이 동물들에게 그렇게 했듯이 완전히 자유로운 경쟁체제에서 초지능이 탑재된 우월한 로봇들이 재료, 에너지, 공간 등을 차지하기 위하여 끝없이 경쟁하며 성장할 것이다. 그리고 이 초지능 로봇의 경쟁에서 인간은 밀려나게 되고 생존이 불가능한 상황이 올 것이다. 

그러나 다행히도 지금의 세금 등의 제도만 봐도 알 수 있듯이 우리는 완전히 자유로운 시장 경쟁체제 속에서 살고 있지 않다. 하지만 정부가 강제적 정책을 현명하게 제시한다면 인간이 로봇을 이용하여 오랫동안 수준 높은 삶을 영위할 수 있다. 

> 만약 완전히 자유로운 시장경쟁 체제로 국가가 운영된다면, 초지능 로봇에 의하여 노동자들부터 시작하여 더욱 고도의 전문성을 가진 사람들까지 점차 경제적 가치를 잃어갈 것입니다. 이에따라 경제적 관점에 한하여 인간은 존재 가치를 완전히 잃어버리게 됩니다. 하지만 인간은 경제 가치를 잃어버린 존재라고 할지라도 폐기되서는 안되는 존재입니다. 그러므로 오로지 경제적 가치를 지닌 존재만 살아남게 되는 완전 자유 시장경쟁 체제는 있어서는 안됩니다.

모라벡은 또 다시 21세기 인류의 과업이 "법률을 통해 로봇들과 지속적 협력을 확보하는 것" 이라고 말했다. 그러고 나서 "초지능이 탑재된 로봇" 이 인간이 얼마나 위험한 존재가 될 것인지 설명한다. 그는 로봇이 인간을 계승하게 될 것이고 잘못하면 인간은 멸종하게 될 것이 틀림없다고 말했다.

### 왜 현 시대 인류는 기술공학 발전이 주는 위협에 관심을 갖지 않는가?

나는 이제 내가 지적으로 존경하는 [대니 힐리스(Danny Hillis)](https://en.wikipedia.org/wiki/Danny_Hillis)에게 이 이야기를 해주었다. 그는 놀랍게도 지금까지 그래왔듯 변화는 점진적으로 올 것이고 인류는 이 변화에 익숙해질 것이라고 말했다. 

그와 대화하며 나는 **현 시대 인류가 왜 로봇에 의한 재앙에 관심을 갖지 않는지** 의문을 제기했다. 이 의문에 대한 부분적인 대답은 **새로운 과학적 발견에 인류가 익숙해져버려서** 로봇공학(인공지능), 유전자공학, 나노테크놀로지가 지금까지의 과학기술과는 **근본적으로 다른 위협을 제기한다는 것을 깨닫지 못하고 있다**는 것이다.

### 기술적 특이점의 실현 가능성에 관하여 (1) - GNR 기술의 원료

커즈와일은 로봇에 영생의 가능성이 있다는 것을 말해주었고, 유전자공학과 나노테크놀로지는 거의 모든 질병의 치유를 제공할 수도 있다는 가능성을 갖고 있다는 것을 말해주었다. 하지만 이런 **기술공학 발전에 인류가 점점 의존하게 될수록 힘과 부는 기술공학 발전을 주도하는 극소수에게 점차 집적되어갈 것**이다. 그리고 이렇게 극소수에게 전무후무한 힘과 부가 집적될수록 엄청난 위험을 초래할 것이다.

**20세기 기술공학의 결정체인 핵(Nuclear), 생화학무기(Biological Chemical) 즉, NBC** 는 인류에 엄청난 위협을 주었지만 정부의 허가와 희긔한 원료물질을 필요로 했다. 따라서 이런 기술 공학을 개발하는 건 국가(정부)였다. 하지만 **21세기 기술공학의 결정체 유전공학(Genetics), 나노테크놀로지(Nanotechnology), 로봇공학(인공지능)(Robotics) 즉, GNR** 은 정부 허가나 희긔한 원료를 필요로 하지 않고 오직 지식만을 필요로 한다. 따라서 현 시대 이런 기술 공학을 개발하는 건 기업(개인)이다.

즉 역사적으로 전무후무할 힘과 부가 국가(정부) 가 아니라 기술공학 개발을 선도하는 극소수의 과학자와 프로그래머들에게 점차 집적되어가고 있다는 것이다. 나는 인류가 극단적 악으로 나아가고 있다는 것이 전혀 과장된 말이 아니라고 생각한다. 왜냐하면 20세기의 대량파괴 무기가 그나마 신뢰할 수 있는 각각의 국가의 정부 통제 하에 있었으나, 21세기 대량파괴 무기는 예측할 수 없는 개인들의 통제 하에 있게 되기 때문이다. 

### 기술적 특이점의 실현 가능성에 관하여 (2) - 초지능을 실행할만큼 강력한 컴퓨터

나는 정보기술이 컴퓨터 과학자나 프로그래머가 아니라 물리학자에 의하여 발전된다는 것을 인식하고 있었다. 최근에 **나는 [브로슬 해슬래처(Brosl Hasslacher)](https://en.wikipedia.org/wiki/Brosl_Hasslacher)와 물리학자 [마크 리드(Mark Reed)](https://en.wikipedia.org/wiki/Mark_Reed_(physicist))에 의해 분자전자공학의 엄청난 가능성**을 알게 되었다. 

나는 세 개의 마이크로프로세서 구조 - SPARC, picoJAVA, MAJC - 의 공동 설계자로서, 무어의 법칙에 대한 직접적 이해를 갖게 되었지만 물리적 한계 때문에 그 법칙이 2010년까지만 유효할 것이라고 예측했다. 하지만 분자전자공학의 급속한 진보에 의해 **기존의 트랜지스터를 원자와 분자가 대체할 수 있다**는 것을 알게 되었고, 나는 무어의 법칙이 30년 이상 유효할 것이라고 믿게 되었다. 그렇게 된다면 **2030년에 오늘날 컴퓨터보다 100만배 이상의 강력한 성능을 가진 기계가 탄생할 것**이고, 그렇게 되면 **커즈와일과 모라벡의 예언이 충분히 실현될 수 있는 물리적인 조건이 갖추어지는 것**이다. 

또한 이 엄청나게 **진보된 컴퓨터가 유전학과 결합될 때 이 결합은 좋든 나쁘든 세계를 완전히 바꾸게 될 것**이다. 왜냐하면 자연세계 법칙에 국한되어 있던 복제와 진화 과정이 인간의 손(어쩌면 로봇의 손)에 의해 좌지우지 될 것이기 때문이다. 

### 기계가 인류를 완전히 대체하는 것에 관하여

소프트웨어와 마이크로프로세서를 설계하면서 나는 지능을 가진 기계를 설계한다는 생각을 하지는 않았다. 그러나 30년 내에 인간 수준 능력을 가진 컴퓨터가 탄생할 것이라는 생각이 들면서, 내게 내가 하는 일이 인간이라는 종을 대체할 수도 있는 존재를 만드는 것이 아닐까 하는 근심이 생기기 시작했다. 

새로운 기술의 엄청난 힘을 생각하면 우리는 마땅이 이것과 어떻게 공존할 수 있는지 물어야만 한다. 또 만약 그 기술 공학이 인류를 멸종하게 할 수 있다면 큰 조심성을 가지고 나아가야만 한다. 

1. 로봇의 첫번째 목표는 지능을 가진 **기계가 인간의 노동을 대체하여 대신 일을 해줌으로써 인간을 쉬게하는 것**이다. 나는 이와 같은 지능을 가진 기계가 2030년까지는 만들어질 것으로 보인다. 

2. 로봇의 두번째 목표는 로봇기술로 인간 자체를 대체하여, **우리의 의식을 다운로드시키고 영생을 누리게 하는 것**이다. 

커즈와일의 [『The Age of Spiritual Machines』(정신적 기계의 시대)](https://en.wikipedia.org/wiki/The_Age_of_Spiritual_Machines) 에 묘사되어있듯 컴퓨터 장치를 몸속에 심은 행위가 이런 과정의 전조를 보여준다. 

## GNR 에 관하여

무엇보다 GNR(유전자공학, 나노테크놀로지, 로봇공학(인공지능)) 기술의 파괴적인 자기복제 능력을 조심해야만 한다. [스튜어트 카우프먼(Stuart Kauffman)](https://en.wikipedia.org/wiki/Stuart_Kauffman)의 논문 《Self-Replication: Even Peptides Do It》(자기복제 - 펩타이드도 한다) 은 32개의 아미노산 펩타이드가 자가촉매작용으로 스스로 합성물을 만드는 것을 토의하고 있다. 특히 극미로봇(nanobots), 인공 유기체는 특별히 더 위험한데 그것이 자기복제를 할 수 있기에 빠른 속도로 통제 불가능하게 되기 때문이다. 네트워크 상에서 프로그램이 자기 복제를 한다면 최악의 경우 네트워크를 중단하면 되지만, 로봇의 자기복제는 중단할 수 없기 때문에 인류의 물리 세계에 직접적인 위협이 될 것이다. 

우리는 여러해 전부터 **GNR 의 위험, 즉 지식만으로 대량 파괴가 가능하다는 위험에 대한 경고를 받아왔지만 이 경고는 널리 알려지지 않았다.** 왜냐하면 대중에게 이 위험을 알리는 것은 이익이 생기는 일이 아니기 때문이다. 기업은 엄청난 돈벌이를 위하여 전지구적 자본주의 체제 속에서 이 새로운 테크놀로지들을 공격적으로 추구하고 있다. 

[칼 세이건(Carl Edward Sagan)](https://ko.wikipedia.org/wiki/%EC%B9%BC_%EC%84%B8%EC%9D%B4%EA%B1%B4)은 1994년에 [『창백한 푸른 점』](https://book.naver.com/bookdb/book_detail.nhn?bid=66722) 에서 다음과 같이 말했다. 

*"새로이 형성된 행성에서 생명이 형성되고, 생명체들은 진화의 과정을 따라가며 지능이 생기고 어느 지점까지 살아남는다. 그리고는 기술이 발명된다. 그들은 실험으로 자연법칙을 드러내고 자연법칙을 모아둔 과학은 그들에게 엄청난 힘을 허용한다. 한순간에 그들은 세계를 변화시킬 수 있는 장치들을 만들어낸다. **몇몇 문명은 해도 되는 것과 해서는 안될 것의 한계를 정하여 위기를 안전하게 통과한다.** 그밖의 **다른 문명은 운이 좋지 않거나 신중하지 못한 결과로 파멸한다.**"*

칼 세이건의 목소리는 웅변적이지만 단순한 상식에서 나왔다. 21세기 기술 발전의 선도자들은 겸손과 더불어 이 상식을 갖고 있지 않다.

### G(유전자공학)에 관하여

유전자공학은 믿을 수 없을 만큼 강력한 힘을 가지고 있기 때문에 그 기술 공학에도 인류에게 중대한 안전 문제가 존재한다. 물리학자 [에머리 로빈스(Amory Lovins)](https://en.wikipedia.org/wiki/Amory_Lovins)와 [헌터 로빈스(Hunter Lovins)](https://en.wikipedia.org/wiki/Hunter_Lovins)는 "새로운 생물종의 개발이 진화의 법칙이 아니라 경제적 이해관계에 따라 이루어진다" 며 생태학적 관점에서 경고하는 논설을 내었다. 이것은 **경제적 가치가 사라진 생물종은 도태되고 결국 멸종한다**는 의미이다. "A Tale of Two Botanies," 의 247 페이지를 보라.

하지만 이미 유전자 공학에 인류는 너무 많이 의존하고 있다. 미국 농무부는 50여개 유전자조작 농산물의 무제한 방출을 승인했고, 세계의 절반 이상 콩과 옥수수가 다른 생명형태에서 떼어낸 유전자 조각을 포함하고 있다. 내가 우려하는 것은 **유전자조작 기술 공학이 군사적으로든, 우발적으로든, 고의적 테러행위로든, 인류 전체에 위협이 될 가공할 재앙을 만들어낼 수 있다**는 것이다. 

### N(나노테크놀로지)에 관하여

나노테크놀로지의 놀라운 기술은 [리처드 파인만(Richard Phillips Feynman)](https://ko.wikipedia.org/wiki/%EB%A6%AC%EC%B2%98%EB%93%9C_%ED%8C%8C%EC%9D%B8%EB%A7%8C)이 1959년 연설에서 처음 언급했다. 1980년 [에릭 드렉슬러(K. Eric Drexler)](https://en.wikipedia.org/wiki/K._Eric_Drexler)는 [『Engines_of_Creation』(창조의 엔진)](https://en.wikipedia.org/wiki/Engines_of_Creation) 에서 원자 수준 물질이 조작됨으로써 어떻게 풍요로운 미래가 창조되는지 묘사했다. 그 풍요로운 미래란 모든 것이 값싸게 만들어지고 모든 질병과 육체적 문제가 나노테크놀로지와 인공지능을 통해 해결되는 미래였다. 

에릭 드렉슬러는 그의 또 다른 책 [『Unbounding the Future: The Nanotechnology Revolution』(무한한 미래 - 나노테크놀로지 혁명)](https://www.amazon.com/Unbounding-Future-Nanotechnology-Eric-Drexler/dp/0688125735) 에서 분자 수준 "어셈블러" 가 값싼 에너지를 창조하고, 암에서부터 감기에 이르는 모든 질병을 치유하고, 값싼 포켓용 슈퍼컴퓨터를 만들어낼 수 있고, 우주비행을 지금의 대양 횡단보다 용이하게 만들고, 멸종된 생물도 복원한다고 말한다. 나는 [『Engines_of_Creation』(창조의 엔진)](https://en.wikipedia.org/wiki/Engines_of_Creation) 을 읽고 인간의 중노동이 사라질 것이라는 생각에 평안함을 느꼈다. 나노테크놀로지는 인류를 믿을 수 없늘 만큼 진보하게 할 것인데, 그 진보가 아마 필연적인 것이라는 사실을 알았기 때문이다. 

그러나 나는 1989년에 여러 물리학자들과 나노테크놀로지에 관한 대화를 나누었고 나노테크놀로지가 그렇게 뜻대로 되지는 않을 것이고, 최소한 그렇게 빨리 되지는 않을 것이라는 것을 확신하게 되었다. 하지만 작년 여름 [브로슬 해슬래처(Brosl Hasslacher)](https://en.wikipedia.org/wiki/Brosl_Hasslacher)로부터 나노스케일 분자전자공학이 이제 실제적인 것이 되었다는 것을 들었다. 이것은 나노테크놀로지에 관한 나의 견해를 다시금 바꾸어 [『Engines_of_Creation』(창조의 엔진)](https://en.wikipedia.org/wiki/Engines_of_Creation) 을 다시 읽게 하였고, 10년도 더 지난 지금 에릭 드렉슬러가 설명하는 "파괴의 엔진" 이 실제로는 그의 설명보다 훨씬 더 위험하다는 것을 깨닫게 되었다. 어셈블러 기술이 20년 내에 출현할 것으로 보이고, 개별 분자가 회로 요소가 되는 분자전자공학은 10년 내에 엄청난 돈벌이가 될 것으로 보인다. 

하지만 불행히도 **핵기술처럼 나노테크놀로지는 긍정적 용도보다 파괴적 용도로 사용되기 더 쉽다.** 가령 특정 지역 또는 특정 유전적 특성을 지닌 인간집단에게 선택적으로 상해를 가할 수 있는 장비도 나노테크놀로지로 쉽게 만들 수 있다. 에릭 드렉슬러는 다음과 같이 말했다.

*"효율성 없는 식물들이 진짜 식물들을 이길 수 있고, 닥치는대로 먹어치우는 박테리아들이 진짜 박테리아들과의 경쟁에서 이길 수 있다. 그것들은 급속히 복제됨으로써 단 며칠 만에 세계를 먼지의 세계로 환원시킬 수 있다."*
  
이런 종말은 온 인류의 종말을 야기하는 우울한 종말이 될 것이나 이런 종말이 한 실험실에서의 단순한 실수와 사고로 야기될 수 있는 시대가 이르렀다. 

## 기술적 특이점에 대한 대안책

[『Engines_of_Creation』(창조의 엔진)](https://en.wikipedia.org/wiki/Engines_of_Creation) 에서 에릭 드렉슬러는 실험실로부터 빠져나가는 모든 위험한 복제물을 차단하기 위하여 나노테크놀로지 방패를 건설할 것을 제안했다. 하지만 나는 이 방패도 그 자체로 매우 위험한 것이 될 것이라 생각한다. 그것이 자가면역 문제를 일으켜 생명권을 공격한다면 그 어떤 것도 막을 수 없기 때문이다. 이런 문제는 로봇공학(인공지능), 유전공학에 대한 방패를 건설하는 데도 똑같이 일어난다. 즉, 내가 보기에 방패 개발의 부작용은 그것이 막아내고자 하는 기술들만큼 위험한 것이 된다는 것이다. 

레이건 행정부에 의해 제안된 전략방어계획(Strategic Defense Initiative) 은 소련의 핵공격에 대한 방패로써 설계된 것인데 이 계획의 토의에 관여했던 [아서 C. 클라크(Sir Arthur Charles Clarke)](https://ko.wikipedia.org/wiki/%EC%95%84%EC%84%9C_C._%ED%81%B4%EB%9D%BC%ED%81%AC)는 이렇게 말했다. 

*"탄도탄들 중 극소수만 통과하게 할 수 있는 지역방어체제를 엄청난 비용을 들여 건설하는 것이 가능하다 해도 전면적 국가방어체제는 넌센스이다. 전면적 방어가 가능할지 몰라도 그것을 이루기 위해 동원된 테크놀로지는 그것의 부산물로써 끔찍한 무기들을 만들게 될 것이고, 그 결과 누구도 **원래의 문제였던 탄도탄같은 원시적인 무기에 관심을 갖지 않게 될 것**이다."*

그러므로 기술적 특이점의 대책이 무엇인가 에 대한 **나의 대답은 기술 발전을 포기하자**는 것이다. 왜냐하면 기술적 특이점을 막으려는 시도들은 전부 다 바람직하지 않거나 성취가 불가능한 것이기 때문이다. 즉, 지식의 발전에 어떤 식으로든 제약을 가함으로써 인류의 멸종을 야기할 수도 있는 위험한 기술 공학의 개발에 제동을 걸어야 한다는 것이다. 만일 우리가 인류라는 하나의 종으로서 무엇을 원하고, 우리가 어떤 미래로 가고 있으며, 왜 그렇게 될 수밖에 없는지에 대하여 동의하게 된다면 더 이상의 지식 발전을 그만두자는 것에도 합의할 수 있을 것이다. 그리고 이로써 미래에 대한 위험을 없앨 수 있다. 

그러나 불행히도 기술 발전을 포기해야 한다는 대책은 이상론인 것 같다. 왜냐하면 **인류의 역사를 미루어 보았을 때 인류는 미래의 평화를 위하여 합의를 할만한 존재가 아닌 것 같기 때문이다.**

### 인류가 미래의 평화를 위하여 합의를 할만한 존재가 아니라는 것에 관하여

만약 인류가 기술발전의 포기에 동의하지 않는다면 20세기에 NBC(핵, 생물, 화학) 기술이 그러했듯이 21세기에 GNR(유전자, 나노테크놀로지, 로봇(인공지능)) 기술 개발이 대학교 간의, 기업 간의, 국가 간의 무기 경쟁으로 전개될 것이다. 이 상황은 우리에게 매우 위험한 미래를 가져다 줄 것이다. 왜냐하면 우리는 **경쟁이 한번 시작되면 그것을 멈출 수 없다**는 것을 알고 있기 때문이다. 멈출 수 없는 이유는 이러하다. 20세기 NBC 기술 개발이 전쟁상황이라는 특수한 상황 때문에 이루어졌었지만 GNR 기술 개발은 우리의 습관, 욕망, 경제체제, 지식에 대한 탐구욕, 돈, 명예 때문에 이루어질 것이기 때문이다. 

나는 인류가 집단적 가치, 윤리, 도덕에 의해 나아갈 길을 결정하는데 합의하길 바란다. **그러나 역사를 미루어 보았을 때 인류가 하나의 종으로써 하나되어 행동하는 것 같지 않아 보인다.** 핵 위협에 관련하여 우리는 서로에게 정직하지 않게 말했고 행동했었다. 이것이 정치적 이유인지, 우리가 미래를 보지 않기로 선택했기 때문인지, 전쟁이라는 두려움 속에서 비합리적으로 행동했기 때문인지 나는 알 수 없지만, 이것은 전혀 좋은 징조가 아니다.

**GNR, 즉 유전자공학, 나노테크놀로지, 로봇공학(인공지능)이라는 판도라의 상자가 열렸는데 인류는 이것에 주목하고 있지 않다. 이것을 상자 속으로 되돌려 놓을 수 없다.** 우라늄과 플루토늄과 달리 이것은 채굴할 필요도 정련할 필요도 없이 단지 지식을 얻고 발전시키기만 하면 된다. 

혹시 인류는 아무런 계획, 제어장치가 없이 이미 너무 멀리왔기 때문에 미래를 바꾸는 것이 불가능한 것이 아닐까? 하지만 나는 그렇다고 믿지 않는다. **미래의 위험을 막기 위하여 지식 발전에 제동을 걸 마지막 기회가 빠른 속도로 오고 있다.**

인류가 희망을 가질 수 있는 좋은 선례가 존재한다. 그것은 미국이 생물학 무기 개발을 무조건적이고 일방적으로 포기한 것이다. 이 포기는 생물학 무기가 한번 만들어진 다음에 쉽게 복제될 수 있고 깡패국가나 테러단체에 넘어갈 수 있다는 깨달음으로부터 나왔고, 우리는 이것을 1972년 "생물무기협약" 과 1993년 "화학무기협약" 에서 구체화시켰다. 

### NBC 기술보다 제한하기 어려운 GNR 기술

나는 오히려 1945년 핵기술을 포기해야하는 상황이 지금보다 더 단순했다고 생각한다. 왜냐하면 핵기술은 상업적 용도와 군사적 용도로 분리될 수 있었고 그것의 감시는 방사능 측정 등을 이용하면 매우 용이했기 때문이다. 하지만 GNR 기술은 상업용과 군사용으로 구분하기가 애매하다. GNR 의 경제적 가치 때문에 국가는 그 기술들을 국가기관(군대 등)에서만 발전시키게 할 수가 없다. 
  
> 왜냐하면 경제 가치란 곧 국가 경쟁력이고 국가 경쟁력의 하락이란 쉽게 말해 이웃 나라가 우리나라를 먹을 수도 있는 상황을 의미하기 때문입니다. 따라서 국가는 개인(기업) 이 연구하는 유전학(G), 나노공학(N), 로봇공학(R) 과 인공지능 연구를 도무지 제한할 수가 없습니다.
  
GNR 기술의 포기를 위해서는 생화학 무기와 핵무기에 대한 감시체계와 비슷한 감시체계가 필요할 것이다. 그러나 이것은 개인 프라이버시와 지식 발전에 대한 욕구, 그리고 우리 모두를 보호하기 위한 감시의 필요성 사이에서 갈등을 일으킬 것이다. 왜냐하면 GNR 기술은 오로지 지식 탐구에 의하여 발전되는 것이기 때문이다. 이 갈등은 곧바로 감시체계를 운영하는 국가에 대한 개인의 자유의 상실로 인한 국민들의 저항을 발생시킬 것이다. 또한 GNR 기술 발전이 오직 지식 탐구에 의해 이루어지므로 물리 공간에 대한 감시 뿐만 아니라 사이버 공간에 대한 감시도 필수불가결할 것이다. 그래서 감시는 더욱 어려워진다.

### GNR 기술의 위험성에 대하여

맨허튼 계획(미국의 핵무기 개발 프로젝트)에 참여한 노벨 물리학상 수상자 [한스 베테(Hans Albrecht Bethe)](https://ko.wikipedia.org/wiki/%ED%95%9C%EC%8A%A4_%EB%B2%A0%ED%85%8C)는 모든 과학자들, 학자들, 대학생들에게 이렇게 호소했다. 

*"핵무기와 그밖의 잠재적으로 대량 파괴력을 가진 무기들의 창조, 개발, 개선, 제조 작업을 중단하고 거기서 물러나야 한다"*

나는 NBC 기술 뿐만 아니라 **GNR 기술, 그리고 기술적 특이점을 야기할 수 있는 인공지능 개발자들까지, 또한 그러한 기술 공학을 막론하고 인류의 멸종을 부르는 위험한 기술을 연구하는 모든 사람들에게 각성된 의식과 개인적인 책임감이 필요하다**고 생각한다. 우리는 장생불사의 꿈도 버려야 한다. 그 꿈에는 너무나 값비싼 대가, 인류의 멸종의 위험이 뒤따르기 때문이다. 

> 하지만 빌 조이가 인류가 불로불사의 꿈을 버려야 한다고 주장한 것과 달리 실제로 빌 조이에게 기술적 특이점에 대한 아이디어를 설득시킨 레이 커즈와일은 장생불사의 꿈에 과할 정도로 집착하고 있는 것으로 유명합니다. (참고 : https://namu.wiki/w/%EB%A0%88%EC%9D%B4%20%EC%BB%A4%EC%A6%88%EC%99%80%EC%9D%BC#s-4.1)

나는 우리가 경제성장의 문화를 초월하여 우리의 창조력을 발휘할 수 있는 대안적인 통로를 찾아야 한다고 생각한다. 경제성장은 수백년간 축복이었지만 항상 행복은 아니었다. 이제 우리는 기술 공학의 무분별한 성장에 따른 명백한 위험을 받아들일 것인지 선택해야만 한다. 

## 커즈와일과의 대화 일 년 후

나는 커즈와일과 대화를 나눈 일 년 후 희망의 징조를 보곤 했다. 경고와 포기에 대한 목소리가 들려오고 현재의 곤경에 대하여 깊이 우려하는 사람들을 발견했다. 그러나 위험을 알고 있으면서 아직 많은 사람들이 침묵을 지키고 있는 것 같다. 대학가에서 생명윤리학자들은 "*당신이 말하는 것은 이미 오래 전부터 전문자들에 의해 이야기되었던 것이다. 당신의 논리와 당신의 우려는 케케묵은 것이다.*" 라며 투덜거렸다. 나는 많은 권위있는 학자들에 의해 이 문제가 거론되어와다는 것을 알지만, 그것이 우리에게 닥친 위험을 무시해도 좋다는 뜻이 되는가? 

원자과학자들이 핵무기를 개발했던 경험은 개인적 책임을 가져야만 한다는 것을 보여준다. 이제 우리는 **우리 프로그래머들 또한 원자과학자들처럼 언젠가부터 극복할 수 없는 문제를 만들어낼 수 있다**는 결론에 도달하였다. 전문가로서 나의 일은 소프트웨어의 신뢰성을 개선하는 것이다. 나는 이 일이 세계를 좀더 안전하고 살기 좋은 장소로 만들 것이라고 믿어왔다. 그러나 만약 그 반대라고 믿게 될 날이 온다면 나는 프로그램을 만드는 일을 도덕적 인간으로서 중지해야만 할 것이다. 지금 나는 그런 날이 올지도 모른다고 생각하고 있다. 

이 모든 것을 생각하며 나는 화가 나기보다 우울해진다. 이제 내게 진보와 기술 공학 발전이란 씁쓸한 어떤 것이다. 나는 테크놀로지 자체에 대한 두려움이나 사랑 같은 감정이 없는 분위기에서 다양한 배경을 가진 사람들과 지금 내가 제기했던 문제들에 관한 큰 토론을 마련하길 원한다. 우리는 아직 모르는 것이 많다. 우리가 성공할지, 실패할지, 테크놀로지의 희생자가 될지 아직 결정되지 않았다. 

나는 다시금 밤늦게 잠을 이루지 못하였고 지금은 거의 새벽 6시이다. 나는 기술적 특이점에 대한 좀 더 나은 해답을 찾아보려고 노력하고 있다. 

> 이것으로 빌 조이의 《Why the future doesn't need us》(왜 우리는 필요없는 존재가 될 것인가?) 을 매우 간추려서 가볍게 살펴보았습니다.

## 개인적인 생각

개인적으로는 인간의 지능 또한 수학적인 모델로 규명할 수 있고 그것을 프로그램으로 기계화시킬 수 있기 때문에 언젠가 기술공학 발전을 스스로 이룰 수 있을만큼의 지능을 인공지능으로 만들 수 있을 거라고 생각하고 있습니다. 그런 상황이 정말 온다면 과거 인류가 불을 발견했을 때 불을 다룰 수 있는 사람이 불을 다루지 못한 사람을 지배했고, 청동기를 발견했을 때 청동기를 다룰 수 있는 사람이 청동기를 다루지 못한 사람을 지배했듯이, 앞으로의 인류는 인공지능을 다루는 사람이 인공지능을 다룰 수 없는 사람을 지배할 수도 있을 것 같다고 조심스럽게 추측해봅니다. 그런데 지금까지의 문명의 전환점(불, 청동기 등)들과 인공지능의 차이점은 잘못하면 인공지능이 인간을 지배하게 될 수도 있다는 사실입니다. 빌 조이의 글에서 통찰할 수 있듯이 앞으로 인공지능을 지배하는 사람과 인공지능에게 지배당하는 사람으로 현실적인 계급이 극명하게 나뉠 수도 있고, 인공지능에게 지배당하는 사람은 그 노동력과 경제적 가치를 완전히 대체 당할 수도 있다고 조심스럽게 예측하고 있습니다. 그렇기에 앞으로는 청동기 전쟁이 아니라, 총 싸움이 아니라, 핵전쟁이 아니라, 화폐전쟁이 아니라, 인공지능 싸움이 일어날 것이라고 조심스럽게 예상하고 있습니다. 그러므로 개인적으로 인공지능 연구를 할 수 있는대로 최대한 해야할 것 같다는 생각을 갖고 있습니다. 

이것이 제가 수학이 시작될 때부터의 과거와 괴델의 불완전성 정리, 튜링의 증명 등으로 시작된 컴퓨터의 역사와 최근까지의 일들에 대한 위대한 석학들의 의견들을 미루어보고 나서 **개인적으로 내린 주관적인** 결론입니다. **그러나 어디까지나 미래에 대한 이야기는 확언할 수 없고 장담할 수도 없으니 다른 사람의 주장을 맹신해서는 안되고 각자가 스스로 판단해야 한다는 것**을 다시 한 번 강조합니다. 여러분의 결론은 무엇이고, 여러분은 과거를 미루어보아 미래가 어떻게 될 거라고 예상하셨으며, 그 예상을 기반으로 오늘 어떻게 행동하는 것이 최선이라고 판단하셨나요? 
